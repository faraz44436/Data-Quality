{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "Already_Processed_files_path = 'D:\\\\faraz_target\\Already_Processed_files.txt'\n",
    "staging_path = 'D:\\\\faraz'\n",
    "target_path='D:\\\\faraz_target\\\\'\n",
    "address_path='D:\\\\faraz_add\\Areas_in_blore.xlsx'\n",
    "df_address=pd.read_excel(address_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_csv_files = []\n",
    "source_csv_files = []\n",
    "##Check if it’s a new file or not. We do not want to reprocess already processed\n",
    "##files.\n",
    "def file_check_module():\n",
    "    global Unprocessed_files\n",
    "    ##checking if File extensions is csv\n",
    "    for name in os.listdir(staging_path):\n",
    "        if name.endswith(\".csv\"):\n",
    "            source_csv_files.append(name)\n",
    "    \n",
    "    processed = open(Already_Processed_files_path, 'r')\n",
    "    processed_files = processed.readlines()\n",
    "    processed.close()\n",
    "    for file in processed_files:\n",
    "        processed_csv_files.append(file)\n",
    "    print(processed_csv_files)\n",
    "    ##Check if it’s a new file or not\n",
    "    Unprocessed_files =list(set(source_csv_files) - set(processed_csv_files))\n",
    "    print(Unprocessed_files)\n",
    "    print(\"Type of Unprocessed_files:\", type(Unprocessed_files))\n",
    "    global Unprocessed_non_empty_file\n",
    "    Unprocessed_non_empty_file=[]\n",
    "    for Unprocessed_file in Unprocessed_files:\n",
    "        full_path=staging_path + \"\\\\\" + Unprocessed_file\n",
    "        print(full_path)\n",
    "        df = pd.read_csv(full_path)\n",
    "        print(df.empty)\n",
    "        ##checking for a non-empty file.\n",
    "        if not(df.empty):\n",
    "            Unprocessed_non_empty_file.append(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['data_file_20210528182844.csv', 'data_file_20210528182864.csv', 'data_file_20210528182554.csv', 'data_file_20210527182730.csv']\n",
      "Type of Unprocessed_files: <class 'list'>\n",
      "D:\\faraz\\data_file_20210528182844.csv\n",
      "False\n",
      "D:\\faraz\\data_file_20210528182864.csv\n",
      "True\n",
      "D:\\faraz\\data_file_20210528182554.csv\n",
      "False\n",
      "D:\\faraz\\data_file_20210527182730.csv\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "file_check_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##removing commas, period, exclamations or any other special/junk characters etc.\n",
    "def Replace_Special_Characters(input):\n",
    "    process = re.sub('[^A-Za-z0-9]+', ' ', input)\n",
    "    return process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing commas, period, exclamations or any other special/junk characters etc.\n",
    "def Replace_Special_Characters_review(input):\n",
    "    process = re.sub('[^A-Za-z0-9]+', ' ', input)\n",
    "    process = re.sub('0 RATED n', '', process)\n",
    "    process = re.sub('  ', ' ', process)\n",
    "    return process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing preceding Plus\n",
    "def Phone_Number_Validation(input):\n",
    "    process = input.lstrip(\"+\")\n",
    "    return process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##My data quality check\n",
    "#We can have checks to remove words like below .\n",
    "##you've -> you have\n",
    "##he's -> he is\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_quality_check():\n",
    "    for to_process in Unprocessed_non_empty_file:\n",
    "        target_file_name = os.path.basename(to_process)\n",
    "        target_file_bad = re.sub('.csv','.bad',target_file_name)\n",
    "        target_file_out = re.sub('.csv','.out',target_file_name)\n",
    "        target_file_metadata = re.sub('.csv','.metadata',target_file_name)\n",
    "        target_full_path_bad = target_path + target_file_bad\n",
    "        target_full_path_out = target_path + target_file_out\n",
    "        target_full_path_meta = target_path + target_file_metadata\n",
    "        print(\"target path is ::\",target_full_path_out)\n",
    "        df = pd.read_csv(to_process)\n",
    "        df['address']= df['address'].map(Replace_Special_Characters)\n",
    "        df['reviews_list']= df['reviews_list'].map(Replace_Special_Characters_review)\n",
    "        df['reviews_list']= df['reviews_list'].map(decontracted)\n",
    "        ##Splitting Phone column\n",
    "        df[['phone_1', 'phone_2']] = df['phone'].str.split('\\r\\n', n=1, expand=True)\n",
    "        df['phone_1']= df['phone_1'].astype(str).map(Phone_Number_Validation)\n",
    "        df['phone_2']= df['phone_2'].astype(str).map(Phone_Number_Validation)\n",
    "        df_name_is_null = df.loc[df['name'].isnull()]\n",
    "        df_phone = df.loc[df['phone_1'].isnull()]\n",
    "        df_location = df.loc[df['location'].isnull()]\n",
    "        df = df.loc[df['location'].notnull()]\n",
    "        df = df.loc[df['phone_1'].notnull()]\n",
    "        df = df.loc[df['location'].notnull()]\n",
    "        ##Validation of location field for correctness of data by looking up to the Areas_in_blore.csv file\n",
    "        df = df.assign(InDF_address=df.location.isin(df_address.Area).astype(int))\n",
    "        df_out = df.loc[df['InDF_address'] == 1]\n",
    "        df_bad = df.loc[df['InDF_address'] == 0]\n",
    "        df_bad_dropped_InDF_address = df_bad\n",
    "        df_bad.index.names = ['Row_num_list']\n",
    "        df_out.drop(['phone', 'InDF_address'], axis=1, inplace=True)\n",
    "        if(df_bad.shape[0] > 0):\n",
    "            df_bad_dropped_InDF_address.to_csv(target_full_path_bad,index=0)\n",
    "            df_bad.loc[df_bad['InDF_address'] == 0, 'Type_of_issue'] = \"Invalid_Address\"\n",
    "            df_bad['Type_of_issue'].to_csv(target_full_path_meta)\n",
    "        ##Checks for null values in fields \n",
    "        if(df_location.shape[0] > 0):\n",
    "            ##Capturing all the bad records to a .bad & metadata file.\n",
    "            df_location.to_csv(target_full_path_bad, mode='a', header=False,index=1)\n",
    "            print(\"Bad data appended at the location::\",target_full_path_bad)\n",
    "            df_location['Type_of_issue']=\"location is null\"\n",
    "            df_location['Type_of_issue'].to_csv(target_full_path_meta, mode='a', header=False,index=1)\n",
    "        ##Checks for null values in fields \n",
    "        if(df_phone.shape[0] > 0):\n",
    "            ##Capturing all the bad records to a .bad & metadata file.\n",
    "            df_phone.to_csv(target_full_path_bad, mode='a', header=False,index=1)\n",
    "            print(\"Bad data appended at the location::\",target_full_path_bad)\n",
    "            df_phone['Type_of_issue']=\"phone number is null\"\n",
    "            df_phone['Type_of_issue'].to_csv(target_full_path_meta, mode='a', header=False,index=1)\n",
    "        ##Checks for null values in fields \n",
    "        if(df_name_is_null.shape[0] > 0):\n",
    "            ##Capturing all the bad records to a .bad & metadata file.\n",
    "            df_name_is_null.to_csv(target_full_path_bad, mode='a', header=False,index=1)\n",
    "            print(\"Bad data appended at the location::\",target_full_path_bad)\n",
    "            df_name_is_null['Type_of_issue']=\"name is null\"\n",
    "            df_name_is_null['Type_of_issue'].to_csv(target_full_path_meta, mode='a', header=False,index=1)\n",
    "        ##Capturing all the clean records to a .out file.\n",
    "        df_out.to_csv(target_full_path_out,index=0)\n",
    "        mark_processed = open(Already_Processed_files_path,\"a\")\n",
    "        mark_processed.writelines(target_file_name)\n",
    "        mark_processed.write(\"\\n\")\n",
    "        mark_processed.close()\n",
    "        print(to_process)\n",
    "        print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target path is :: D:\\faraz_target\\data_file_20210528182844.out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faraz Khan\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\Faraz Khan\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\Faraz Khan\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad data appended at the location:: D:\\faraz_target\\data_file_20210528182844.bad\n",
      "D:\\faraz\\data_file_20210528182844.csv\n",
      "(7378, 20)\n",
      "target path is :: D:\\faraz_target\\data_file_20210528182554.out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faraz Khan\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\Faraz Khan\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\Faraz Khan\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad data appended at the location:: D:\\faraz_target\\data_file_20210528182554.bad\n",
      "D:\\faraz\\data_file_20210528182554.csv\n",
      "(7376, 20)\n",
      "target path is :: D:\\faraz_target\\data_file_20210527182730.out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faraz Khan\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "C:\\Users\\Faraz Khan\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1596: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\Faraz Khan\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad data appended at the location:: D:\\faraz_target\\data_file_20210527182730.bad\n",
      "D:\\faraz\\data_file_20210527182730.csv\n",
      "(7378, 20)\n"
     ]
    }
   ],
   "source": [
    "data_quality_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
